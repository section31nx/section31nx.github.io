<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Error Handling | Python Proxy Tutorials With MontgomeryNX</title>
  <meta name="description" content="Learn how to catch and react to HTTP errors, timeouts, quota limits (402) and more when using ProxyHub in your Python scraper.">
  <link rel="canonical" href="https://www.montgomerynx.com/python-proxy-tutorial/Error-Handling.html">
  <link rel="icon" href="/favicon.ico" />

  <!-- shared base + navbar + code styles -->
  <link rel="stylesheet" href="/assets/css/tutorial.css">
  <!-- only error-handling page overrides -->
  <link rel="stylesheet" href="/assets/css/error-handling.css">

  <!-- BreadcrumbList schema.org JSON-LD -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
      { "@type": "ListItem", "position": 1, "name": "Home",                   "item": "https://www.montgomerynx.com/" },
      { "@type": "ListItem", "position": 2, "name": "Python Proxy Tutorials", "item": "https://www.montgomerynx.com/python-proxy-tutorial/" },
      { "@type": "ListItem", "position": 3, "name": "Error Handling",         "item": "https://www.montgomerynx.com/python-proxy-tutorial/Error-Handling.html" }
    ]
  }
  </script>
</head>
<body>
  <!-- Navbar -->
  <nav class="tutorial-nav">
    <div class="nav-container">
      <a href="/python-proxy-tutorial/" class="logo">Python Proxy Tutorials</a>
      <button class="burger" aria-label="Toggle menu">
        <span></span><span></span><span></span>
      </button>
      <ul class="nav-links">
        <li><a href="/python-proxy-tutorial/getting-started.html">Getting Started</a></li>
        <li><a href="/python-proxy-tutorial/How-to-rotate-proxies-in-Python.html">Rotate Proxies</a></li>
        <li><a href="/python-proxy-tutorial/Error-Handling.html" class="active">Error Handling</a></li>
        <li><a href="/python-proxy-tutorial/Advanced.html">Advanced</a></li>
      </ul>
    </div>
  </nav>

  <main class="container">
    <h1>Error Handling with ProxyHub in Python</h1>

    <p>Robust scrapers need to gracefully handle HTTP errors, timeouts, and quota limits. In this guide, weâ€™ll cover how to catch and react to common proxy-related errors when using ProxyHub.</p>

    <h2>ðŸ“– Table of Contents</h2>
    <ul>
      <li><a href="#common-errors">Common Error Types</a></li>
      <li><a href="#basic-exception-handling">Basic Exception Handling</a></li>
      <li><a href="#retry-with-backoff">Retries &amp; Exponential Backoff</a></li>
      <li><a href="#quota-exceeded">Handling Quota Exceeded (402)</a></li>
      <li><a href="#timeouts-and-connection-failures">Timeouts &amp; Connection Failures</a></li>
      <li><a href="#best-practices">Best Practices</a></li>
    </ul>

    <h2 id="common-errors">Common Error Types</h2>
    <ul>
      <li><strong>4xx Client Errors</strong> â€“ bad request, unauthorized, rate limit</li>
      <li><strong>5xx Server Errors</strong> â€“ proxy service unavailable, gateway timeout</li>
      <li><strong>Timeouts</strong> â€“ network latency or proxy unresponsive</li>
      <li><strong>Quota Exceeded</strong> â€“ HTTP 402 when you hit your API limit</li>
    </ul>

    <h2 id="basic-exception-handling">Basic Exception Handling</h2>
    <pre><code>import requests

try:
    resp = requests.get(proxied_url, timeout=10)
    resp.raise_for_status()
    data = resp.json()
except requests.exceptions.HTTPError as e:
    print("HTTP error:", e)
except requests.exceptions.Timeout:
    print("Request timed out")
except requests.exceptions.RequestException as e:
    print("Something went wrong:", e)
</code></pre>

    <h2 id="retry-with-backoff">Retries &amp; Exponential Backoff</h2>
    <p>Wrap your calls in a retry loop:</p>
    <pre><code>import time

def fetch_with_retries(url, retries=3, backoff_factor=1):
    for i in range(retries):
        try:
            r = requests.get(url, timeout=10)
            r.raise_for_status()
            return r.text
        except Exception as e:
            wait = backoff_factor * (2 ** i)
            print(f"Attempt {i+1} failed: {e}. Retrying in {wait}sâ€¦")
            time.sleep(wait)
    raise RuntimeError("All retries failed")
</code></pre>

    <h2 id="quota-exceeded">Handling Quota Exceeded <code>402</code></h2>
    <p>Detect and back off when your plan limits are hit:</p>
    <pre><code>r = requests.get(url)
if r.status_code == 402:
    print("Quota exceeded! Waiting 1 hour before retry.")
    time.sleep(3600)
    r = requests.get(url)
</code></pre>
    <div class="note">
      <strong>Note:</strong> You can also monitor your usage via the ProxyHub dashboard and alert proactively.
    </div>

    <h2 id="timeouts-and-connection-failures">Timeouts &amp; Connection Failures</h2>
    <p>Set sensible timeouts and catch connection errors:</p>
    <pre><code>try:
    r = requests.get(url, timeout=5)
except requests.exceptions.ConnectTimeout:
    print("Connection timed out while connecting")
except requests.exceptions.ReadTimeout:
    print("Server took too long to send data")
</code></pre>

    <h2 id="best-practices">Best Practices</h2>
    <ul>
      <li>Always <code>raise_for_status()</code> to fail fast on HTTP errors.</li>
      <li>Use a retry + backoff strategy to avoid hammering the service.</li>
      <li>Catch <code>402 Quota exceeded</code> separately and alert or pause your scraper.</li>
      <li>Log all exceptions with context (URL, headers, response code).</li>
    </ul>

    <p>With these patterns youâ€™ll be equipped to handle most proxy-related failures and keep your scraper resilient.</p>
  </main>

  <!-- Burger toggle script -->
  <script>
    document.querySelector('.burger').addEventListener('click', function(){
      this.classList.toggle('open');
      document.querySelector('.nav-links').classList.toggle('show');
    });
  </script>
</body>
</html>
